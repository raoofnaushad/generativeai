{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM and Prompts and Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Lets quickly load a markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/raoofmac/Documents/coding/learning/genai/data/README.md', \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see default Prompts in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Prompt\n",
    "\n",
    "text_qa_template = Prompt(\n",
    "    \"Context Information is below. \\n\"\n",
    "    \"-----------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "refine_template = Prompt(\n",
    "    \"We have the opportunity to refine the original answer \"\n",
    "    \"(only if needed) with some more context below. \\n\"\n",
    "    \"----------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"----------------\\n\"\n",
    "    \"Given the next context, refine the original answer to better \"\n",
    "    \"answer the question: {query_str}.\\n\"\n",
    "    \"If the context isn't useful, output the original answer again. \\n\"\n",
    "    \"Original Answer: {existing_answer}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA Template Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To set up the GenerativeAI repository, you can follow these steps:\n",
      "\n",
      "1. Clone the repository by running the following command in your terminal or command prompt:\n",
      "   ```\n",
      "   git clone https://github.com/raoofnaushad/generativeai.git\n",
      "   ```\n",
      "\n",
      "2. Once the repository is cloned, navigate to the directory where it is located:\n",
      "   ```\n",
      "   cd generativeai\n",
      "   ```\n",
      "\n",
      "3. Explore the individual projects within the repository by going into their respective directories. Each project directory will have its own README file with details on the project's purpose, how to run the code, and the concepts explored.\n",
      "\n",
      "That's it! You are now set up to explore the projects in the GenerativeAI repository.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I setup the generative ai repo?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To setup the Generative AI repository, you can use the following code:\n",
      "\n",
      "```bash\n",
      "git clone https://github.com/raoofnaushad/generativeai.git\n",
      "```"
     ]
    }
   ],
   "source": [
    "question = \"How can I setup the generative ai repo? Write your answer only using code\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response_gen = llm.stream_complete(prompt)\n",
    "\n",
    "for response in response_gen:\n",
    "    print(response.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined Template Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To setup the Generative AI repository, you can use the following code:\n",
      "\n",
      "```bash\n",
      "git clone https://github.com/raoofnaushad/generativeai.git\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I setup the generative ai repo? Write your answer only using code\"\n",
    "existing_answer = \"\"\"To setup the Generative AI repository, you can use the following code\n",
    "    git clone https://github.com/raoofnaushad/generativeai.git  \n",
    "\"\"\"\n",
    "prompt = refine_template.format(context_msg=text, query_str=question, existing_answer=existing_answer)\n",
    "response = llm.complete(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: To make use of a repository, follow these steps:\n",
      "\n",
      "1. Clone the repository: Start by cloning the repository to your local machine. Open your terminal or command prompt and navigate to the directory where you want to clone the repository. Use the following command to clone the repository:\n",
      "\n",
      "   ```\n",
      "   git clone <repository-url>\n",
      "   ```\n",
      "\n",
      "   Replace `<repository-url>` with the URL of the repository you want to clone. This will create a local copy of the repository on your machine.\n",
      "\n",
      "2. Explore the repository: Once the repository is cloned, navigate to the repository's directory using the `cd` command in your terminal or file explorer. Take a look at the files and directories within the repository. This will give you an idea of what the repository contains.\n",
      "\n",
      "3. Read the documentation: Look for any documentation or README files within the repository. These files often provide instructions on how to use the repository, including installation steps, dependencies, and usage examples. Read through the documentation to understand how to make use of the repository effectively.\n",
      "\n",
      "4. Install dependencies: If the repository has any dependencies, make sure to install them. The documentation or README file should provide instructions on how to install the required dependencies. Follow those instructions to ensure that the repository functions correctly.\n",
      "\n",
      "5. Use the repository: Depending on the purpose of the repository, there are different ways to make use of it. Here are a few common scenarios:\n",
      "\n",
      "   - If the repository is a library or package, you can import and use its functions or classes in your own code. Refer to the documentation or README file for usage examples and instructions on how to integrate the repository into your project.\n",
      "\n",
      "   - If the repository is an application, you can run it locally on your machine. Again, refer to the documentation or README file for instructions on how to set up and run the application.\n",
      "\n",
      "   - If the repository is a template or starter project, you can use it as a foundation for your own project. Copy the repository to a new directory and modify it according to your needs. The documentation or README file should provide guidance on how to customize the template.\n",
      "\n",
      "6. Contribute (optional): If you want to contribute to the repository, follow the guidelines provided in the repository's documentation or README file. This may involve creating a new branch, making changes, and submitting a pull request.\n",
      "\n",
      "Remember to regularly update your local copy of the repository by pulling the latest changes from the remote repository. Use the following command to pull changes:\n",
      "\n",
      "```\n",
      "git pull\n",
      "```\n",
      "\n",
      "By following these steps, you can effectively make use of a repository and leverage its functionality for your own projects.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(role=\"system\", context=\"You are a helpful QA chatbot that can answer questions about Generative AI Repository\"),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me how to make use of this repository\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(chat_history)\n",
    "print(response.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
